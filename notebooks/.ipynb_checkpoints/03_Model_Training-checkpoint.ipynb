{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5863ac-5bdc-4491-9d90-07f0b29ad480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed features shape: (20631, 173)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit</th>\n",
       "      <th>op_set_1</th>\n",
       "      <th>op_set_2</th>\n",
       "      <th>op_set_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_12_max_20</th>\n",
       "      <th>sensor_13_max_20</th>\n",
       "      <th>sensor_14_max_20</th>\n",
       "      <th>sensor_15_max_20</th>\n",
       "      <th>sensor_16_max_20</th>\n",
       "      <th>sensor_17_max_20</th>\n",
       "      <th>sensor_18_max_20</th>\n",
       "      <th>sensor_19_max_20</th>\n",
       "      <th>sensor_20_max_20</th>\n",
       "      <th>sensor_21_max_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit  op_set_1  op_set_2  op_set_3  sensor_1  sensor_2  sensor_3  sensor_4  \\\n",
       "0     1   -0.0007   -0.0004     100.0    518.67    641.82   1589.70   1400.60   \n",
       "1     1    0.0019   -0.0003     100.0    518.67    642.15   1591.82   1403.14   \n",
       "2     1   -0.0043    0.0003     100.0    518.67    642.35   1587.99   1404.20   \n",
       "3     1    0.0007    0.0000     100.0    518.67    642.35   1582.79   1401.87   \n",
       "4     1   -0.0019   -0.0002     100.0    518.67    642.37   1582.85   1406.22   \n",
       "\n",
       "   sensor_5  sensor_6  ...  sensor_12_max_20  sensor_13_max_20  \\\n",
       "0     14.62     21.61  ...            521.66           2388.02   \n",
       "1     14.62     21.61  ...            522.28           2388.07   \n",
       "2     14.62     21.61  ...            522.42           2388.07   \n",
       "3     14.62     21.61  ...            522.86           2388.08   \n",
       "4     14.62     21.61  ...            522.86           2388.08   \n",
       "\n",
       "   sensor_14_max_20  sensor_15_max_20  sensor_16_max_20  sensor_17_max_20  \\\n",
       "0           8138.62            8.4195              0.03             392.0   \n",
       "1           8138.62            8.4318              0.03             392.0   \n",
       "2           8138.62            8.4318              0.03             392.0   \n",
       "3           8138.62            8.4318              0.03             392.0   \n",
       "4           8138.62            8.4318              0.03             393.0   \n",
       "\n",
       "   sensor_18_max_20  sensor_19_max_20  sensor_20_max_20  sensor_21_max_20  \n",
       "0            2388.0             100.0             39.06           23.4190  \n",
       "1            2388.0             100.0             39.06           23.4236  \n",
       "2            2388.0             100.0             39.06           23.4236  \n",
       "3            2388.0             100.0             39.06           23.4236  \n",
       "4            2388.0             100.0             39.06           23.4236  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 03_Model_Training.ipynb\n",
    "# Model training, time-series CV, threshold tuning, final test evaluation\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "DATA_DIR = \"../data/processed\"\n",
    "features_path = os.path.join(DATA_DIR, \"train_features_FD001_no_leak.csv\")\n",
    "\n",
    "df = pd.read_csv(features_path)\n",
    "print(\"Processed features shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea4ea527-a31c-478b-bf0f-b6811dd372ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (20631, 172)\n",
      "Class balance (0=healthy, 1=failure): [17531  3100]\n"
     ]
    }
   ],
   "source": [
    "# ----- Separate features and target -----\n",
    "\n",
    "# 'label' is the binary target column we created in file 2\n",
    "y = df[\"label\"].values\n",
    "X = df.drop(columns=[\"label\"]).values\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Class balance (0=healthy, 1=failure):\", np.bincount(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d78bef5-703b-40fe-a723-4123015d214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 F1-score (failure class=1): 0.8459\n",
      "Fold 2 F1-score (failure class=1): 0.8844\n",
      "Fold 3 F1-score (failure class=1): 0.8366\n",
      "Fold 4 F1-score (failure class=1): 0.8274\n",
      "Fold 5 F1-score (failure class=1): 0.8323\n",
      "\n",
      "Mean CV F1-score (failure class=1): 0.845315440921034\n"
     ]
    }
   ],
   "source": [
    "# ----- Time-series cross validation (RandomForest baseline model) -----\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "fold_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_tr, X_val = X[train_idx], X[val_idx]\n",
    "    y_tr, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=None,\n",
    "        n_jobs=-1,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "\n",
    "    f1 = f1_score(y_val, y_val_pred, pos_label=1)\n",
    "    fold_scores.append(f1)\n",
    "\n",
    "    print(f\"Fold {fold} F1-score (failure class=1): {f1:.4f}\")\n",
    "\n",
    "print(\"\\nMean CV F1-score (failure class=1):\", np.mean(fold_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef0a964-b574-4fed-9ff6-d99d1bcab1df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (16504, 172) (16504,)\n",
      "Test shape : (4127, 172) (4127,)\n",
      "Train label counts: [13993  2511]\n",
      "Test label counts : [3538  589]\n"
     ]
    }
   ],
   "source": [
    "# ----- Hold-out test split (respect time order, no shuffling) -----\n",
    "\n",
    "# Use last 20% of rows as test (later in time)\n",
    "test_size = 0.2\n",
    "split_index = int(len(X) * (1 - test_size))\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape :\", X_test.shape,  y_test.shape)\n",
    "print(\"Train label counts:\", np.bincount(y_train))\n",
    "print(\"Test label counts :\", np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2073ed64-9e00-4d29-b246-241c8e572f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching best decision threshold on validation set...\n",
      "Best threshold on validation: 0.60 with F1=0.8451\n"
     ]
    }
   ],
   "source": [
    "# ----- Train final RandomForest + threshold tuning ----- \n",
    "\n",
    "# Split train into (subtrain, val) for threshold search, no shuffle\n",
    "X_subtrain, X_val, y_subtrain, y_val = train_test_split(\n",
    "    X_train, y_train,\n",
    "    test_size=0.2,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "final_model = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "final_model.fit(X_subtrain, y_subtrain)\n",
    "\n",
    "# Predict probabilities for failure class (1)\n",
    "y_val_proba = final_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "best_f1 = -1\n",
    "best_thr = 0.5\n",
    "\n",
    "print(\"Searching best decision threshold on validation set...\")\n",
    "for thr in np.linspace(0.1, 0.9, 17):  # 0.1, 0.15, ..., 0.9\n",
    "    y_val_pred_thr = (y_val_proba >= thr).astype(int)\n",
    "    f1 = f1_score(y_val, y_val_pred_thr, pos_label=1)\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        best_thr = thr\n",
    "\n",
    "print(f\"Best threshold on validation: {best_thr:.2f} with F1={best_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a782e2b-d4d1-4cbd-8422-ae36ca2d6d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test F1-score (failure class=1, thr=0.60): 0.8435498627630376\n",
      "\n",
      "Classification report (test set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.965     0.988     0.976      3538\n",
      "           1      0.915     0.783     0.844       589\n",
      "\n",
      "    accuracy                          0.959      4127\n",
      "   macro avg      0.940     0.885     0.910      4127\n",
      "weighted avg      0.958     0.959     0.957      4127\n",
      "\n",
      "Confusion matrix (test set):\n",
      "[[3495   43]\n",
      " [ 128  461]]\n"
     ]
    }
   ],
   "source": [
    "# ----- Final evaluation on HOLD-OUT test set ----- \n",
    "\n",
    "# Retrain model on entire X_train with chosen hyperparameters\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on test\n",
    "y_test_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= best_thr).astype(int)\n",
    "\n",
    "print(f\"\\nTest F1-score (failure class=1, thr={best_thr:.2f}):\",\n",
    "      f1_score(y_test, y_test_pred, pos_label=1))\n",
    "\n",
    "print(\"\\nClassification report (test set):\")\n",
    "print(classification_report(y_test, y_test_pred, digits=3))\n",
    "\n",
    "print(\"Confusion matrix (test set):\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99583a51-c5f6-461b-a478-3812c2c4003a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote feature list -> ..\\models\\rf_FD001_features.json len: 172\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "MODELS_DIR = os.path.join(\"..\",\"models\")\n",
    "os.makedirs(MODELS_DIR, exist_ok=True)\n",
    "\n",
    "# feature_cols should be defined in your notebook (e.g. `feature_cols = X.columns.tolist()`)\n",
    "# If not, derive from your processed CSV:\n",
    "csv_path = os.path.join(\"..\",\"data\",\"processed\",\"train_features_FD001_no_leak.csv\")\n",
    "if 'feature_cols' not in globals():\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(csv_path, nrows=5)\n",
    "    if \"label\" in df.columns:\n",
    "        feature_cols = [c for c in df.columns if c != \"label\"]\n",
    "    else:\n",
    "        feature_cols = list(df.columns)\n",
    "\n",
    "json_path = os.path.join(MODELS_DIR, \"rf_FD001_features.json\")\n",
    "with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(feature_cols, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Wrote feature list ->\", json_path, \"len:\", len(feature_cols))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
